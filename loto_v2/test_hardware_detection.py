#!/usr/bin/env python3
"""
Test de dÃ©tection hardware universelle
Compatible : Mac M4 Pro (MPS), RTX 4080 (CUDA), CPU multi-cÅ“urs
"""

import sys
import torch
import platform
from pathlib import Path

# Ajouter le chemin des modules
sys.path.append(str(Path(__file__).parent))

from modules.finetuning import LotoFineTuner


def test_comprehensive_hardware_detection():
    """Test complet de dÃ©tection hardware"""
    print("=" * 70)
    print("ğŸ” DÃ‰TECTION HARDWARE UNIVERSELLE")
    print("=" * 70)
    print()
    
    # Informations systÃ¨me de base
    print("ğŸ“‹ Informations systÃ¨me :")
    print(f"   OS : {platform.system()} {platform.release()}")
    print(f"   Architecture : {platform.machine()}")
    print(f"   Processeur : {platform.processor()}")
    print(f"   Python : {sys.version.split()[0]}")
    print(f"   PyTorch : {torch.__version__}")
    
    # Test des capacitÃ©s GPU
    print(f"\nğŸ” Test des capacitÃ©s GPU :")
    
    # CUDA (NVIDIA)
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"   ğŸŸ¢ CUDA disponible : {gpu_count} GPU(s)")
        for i in range(gpu_count):
            name = torch.cuda.get_device_name(i)
            memory = torch.cuda.get_device_properties(i).total_memory / 1e9
            print(f"      GPU {i}: {name} ({memory:.1f} GB VRAM)")
        print(f"   âš¡ Version CUDA : {torch.version.cuda}")
    else:
        print("   âŒ CUDA non disponible")
    
    # MPS (Apple Silicon)
    if hasattr(torch, 'mps'):
        if torch.mps.is_available():
            print("   ğŸŸ¢ MPS (Metal) disponible")
        else:
            print("   ğŸŸ¡ MPS existe mais non disponible")
    else:
        print("   âŒ MPS non disponible")
    
    # CPU
    cpu_count = torch.get_num_threads()
    print(f"   ğŸŸ¢ CPU : {cpu_count} threads PyTorch")
    
    print(f"\n" + "â”€" * 70)
    print("ğŸš€ CONFIGURATION AUTOMATIQUE OPTIMALE")
    print("â”€" * 70)
    
    # Test du systÃ¨me de dÃ©tection
    fine_tuner = LotoFineTuner()
    config = fine_tuner.backend_config
    
    print(f"\nğŸ¯ Configuration dÃ©tectÃ©e :")
    print(f"   Backend : {config['backend'].upper()}")
    print(f"   Device : {config['device'].upper()}")
    print(f"   Hardware : {config['device_name']}")
    print(f"   Batch size : {config['batch_size']}")
    print(f"   Type GPU : {config['gpu_type']}")
    if 'memory_gb' in config:
        print(f"   VRAM : {config['memory_gb']:.1f} GB")
    
    # Recommandations selon le hardware
    print(f"\nğŸ’¡ Optimisations dÃ©tectÃ©es :")
    if config['gpu_type'] == 'nvidia_cuda':
        memory_gb = config.get('memory_gb', 0)
        if memory_gb >= 16:
            print("   ğŸš€ GPU haute performance dÃ©tectÃ©")
            print("   âœ… Batch size Ã©levÃ© pour maximum de vitesse")
            print("   âœ… IdÃ©al pour gros volumes de prÃ©dictions")
        elif memory_gb >= 12:
            print("   ğŸš€ GPU RTX 4080 class dÃ©tectÃ©")
            print("   âœ… Configuration optimisÃ©e pour performance")
            print("   âœ… Excellent pour fine-tuning")
        else:
            print("   ğŸ”§ GPU NVIDIA standard")
            print("   âœ… Configuration Ã©quilibrÃ©e")
    elif config['gpu_type'] == 'apple_mps':
        print("   ğŸ Apple Silicon optimisÃ©")
        print("   âœ… Metal Performance Shaders")
        print("   âœ… EfficacitÃ© Ã©nergÃ©tique maximale")
    else:
        print("   ğŸ–¥ï¸  CPU multi-threading optimisÃ©")
        print("   âœ… Batch size adaptÃ© aux cÅ“urs disponibles")
    
    return config


def test_performance_comparison():
    """Test de performance selon le hardware"""
    print(f"\n" + "=" * 70)
    print("âš¡ ESTIMATION DES PERFORMANCES")
    print("=" * 70)
    
    config = test_comprehensive_hardware_detection()
    
    # Estimations selon le hardware
    if config['gpu_type'] == 'nvidia_cuda':
        memory_gb = config.get('memory_gb', 0)
        if memory_gb >= 16:
            speed = "ğŸš€ TrÃ¨s rapide"
            fine_tuning_time = "~2-3 minutes"
            predictions_100 = "~10-20 secondes"
        elif memory_gb >= 12:
            speed = "âš¡ Rapide"  
            fine_tuning_time = "~3-5 minutes"
            predictions_100 = "~20-30 secondes"
        else:
            speed = "ğŸ”§ Correct"
            fine_tuning_time = "~5-8 minutes"
            predictions_100 = "~30-60 secondes"
    elif config['gpu_type'] == 'apple_mps':
        speed = "ğŸ Efficace"
        fine_tuning_time = "~4-6 minutes"
        predictions_100 = "~25-40 secondes"
    else:
        cpu_threads = torch.get_num_threads()
        if cpu_threads >= 16:
            speed = "ğŸ–¥ï¸  CPU rapide"
            fine_tuning_time = "~8-12 minutes"
            predictions_100 = "~1-2 minutes"
        else:
            speed = "ğŸ–¥ï¸  CPU standard"
            fine_tuning_time = "~12-20 minutes" 
            predictions_100 = "~2-4 minutes"
    
    print(f"\nğŸ“Š Estimations de performance :")
    print(f"   Vitesse gÃ©nÃ©rale : {speed}")
    print(f"   Fine-tuning (5 epochs) : {fine_tuning_time}")
    print(f"   100 prÃ©dictions : {predictions_100}")
    print(f"   Batch size optimal : {config['batch_size']}")
    
    print(f"\nğŸ¯ Recommandations d'usage :")
    if config['batch_size'] >= 12:
        print("   âœ… Parfait pour gros volumes de prÃ©dictions")
        print("   âœ… Fine-tuning rapide recommandÃ©")
    elif config['batch_size'] >= 8:
        print("   âœ… Bon Ã©quilibre performance/stabilitÃ©")
        print("   âœ… IdÃ©al pour usage quotidien")
    else:
        print("   ğŸ”§ Configuration conservatrice")
        print("   ğŸ’¡ RÃ©duire le nombre de prÃ©dictions si lent")


def main():
    """Test principal de dÃ©tection hardware"""
    try:
        test_comprehensive_hardware_detection()
        test_performance_comparison()
        
        print(f"\nğŸ‰ DÃ©tection hardware terminÃ©e !")
        print("   âœ… Configuration automatique optimale")
        print("   âœ… Compatible Mac M4 Pro + RTX 4080 + CPU")
        print("   âœ… Performance maximale selon votre hardware")
        
    except Exception as e:
        print(f"âŒ Erreur lors de la dÃ©tection : {e}")


if __name__ == "__main__":
    main()